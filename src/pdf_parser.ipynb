{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c1a9f1b",
   "metadata": {},
   "source": [
    "## TEST PYMUPDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df60d5e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Blob 4413953808 ../data/cv.pdf"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents.base import Blob\n",
    "\n",
    "blob = Blob.from_path(\"../data/cv.pdf\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fef2a384",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders.parsers import PyMuPDFParser\n",
    "\n",
    "parser = PyMuPDFParser(\n",
    "    mode = \"single\",\n",
    "    pages_delimiter = \"\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32992993",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "docs_lazy = parser.lazy_parse(blob)\n",
    "\n",
    "for doc in docs_lazy:\n",
    "    docs.append(doc)\n",
    "print(docs[0].page_content[:10000])\n",
    "#print(docs[0].metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519c0f19",
   "metadata": {},
   "source": [
    "## TEST GEMINI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "89c560f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Come gather 'round, ye coding kin, and listen to my tale,\\nOf LangChain, a powerful tool, that shall not ever fail.\\nFrom scattered data, knowledge blooms, a symphony so grand,\\nA digital maestro's baton, held firmly in its hand.\\n\\nThe AI models, vast and deep, with wisdom they possess,\\nBut often lost in rambling thoughts, and failing to express\\nTheir true potential, locked away, in circuits cold and stark,\\nUntil LangChain arrived one day, to light the guiding spark.\\n\\nIt weaves together chains of thought, a logic clean and bright,\\nConnecting prompts and agents bold, to conquer darkest night.\\nIt chains the documents together, a sprawling, tangled mess,\\nAnd finds the answers hidden there, with effortless finesse.\\n\\nImagine RAG, Retrieval so advanced, a search that knows no bounds,\\nThrough vector stores and embeddings deep, where information resounds.\\nIt queries knowledge, old and new, with speed and accuracy,\\nAnd brings the relevant answers forth, for all the world to see.\\n\\nThen agents rise, with tools in hand, to tackle tasks complex,\\nFrom searching web to crafting code, with skills that none can vex.\\nThey plan and ponder, step by step, a reasoning so clear,\\nAnd execute their missions true, dispelling doubt and fear.\\n\\nWith memory long, it keeps the past, a context strong and deep,\\nSo conversations flow and grow, secrets it will keep.\\nIt learns from every interaction, refining as it goes,\\nA partner loyal, steadfast true, wherever knowledge flows.\\n\\nThough Python's tongue is often used, to wield this potent art,\\nThe concepts shine, a beacon bright, within the coding heart.\\nFrom chatbots smart to data quests, its applications wide,\\nLangChain empowers us to build, with creativity and pride.\\n\\nSo raise a glass to LangChain's name, a tool both strong and free,\\nThat helps us harness AI's might, for all eternity.\\nGo forth and build, with confidence, and let your projects gleam,\\nFor LangChain stands beside you now, a coder's waking dream!\", additional_kwargs={}, response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []}, id='run--941890fb-d4fc-4298-9897-938e04dc4a24-0', usage_metadata={'input_tokens': 7, 'output_tokens': 450, 'total_tokens': 457, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "GEMINI_API_KEY = os.environ[\"GEMINI_API_KEY\"]\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.0-flash-001\", google_api_key=GEMINI_API_KEY)\n",
    "llm.invoke(\"Write me a ballad about LangChain\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2ea0e667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here's a long haiku about user-generated content, focusing on the \"world\" aspect you provided. It tries to capture the vastness and diverse perspectives found in user content:\n",
      "\n",
      "Worlds bloom from screens,\n",
      "Voices rise, a chorus vast,\n",
      "Truths and fables mix.\n",
      "Each click, a new path,\n",
      "Stories spun from hearts laid bare,\n",
      "Empires are built.\n",
      "Opinions clash loud,\n",
      "Echo chambers softly hum,\n",
      "A global mosaic.\n",
      "Memes take flight swiftly,\n",
      "Trends ignite like brushwood fires,\n",
      "Culture reshaped now.\n",
      "Algorithms sift,\n",
      "Striving to make sense of all,\n",
      "The human ocean.\n",
      "Creators pour forth,\n",
      "Sharing visions, dreams, and fears,\n",
      "A world without walls.\n",
      "This digital sphere,\n",
      "Reflects back our hopes and flaws,\n",
      "The world in our hands.\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    (\"system\", \"Write a long long haiku about users content.\"),\n",
    "    (\"human\", \"world\"),\n",
    "]\n",
    "\n",
    "\n",
    "out = llm.invoke(messages)\n",
    "print(out.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cb43c60b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Okay' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--7ee96e0b-28ee-4eb7-a185-95539748472c' usage_metadata={'input_tokens': 12, 'output_tokens': 0, 'total_tokens': 12, 'input_token_details': {'cache_read': 0}}\n",
      "content=\", here's a long, long haiku about user-generated content in\" additional_kwargs={} response_metadata={'safety_ratings': []} id='run--7ee96e0b-28ee-4eb7-a185-95539748472c' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
      "content=' the world:\\n\\nPixels bloom and fade,\\nVoices rise, a digital\\n' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--7ee96e0b-28ee-4eb7-a185-95539748472c' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
      "content='Choir, then soft hush falls.\\n\\nLinks weave tapestries,\\nOf thoughts and dreams, shared stories,\\nWorld remade, online.\\n\\nMem' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--7ee96e0b-28ee-4eb7-a185-95539748472c' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
      "content='es flash, fleeting bright,\\nViral trends ignite the web,\\nThen, forgotten dust.\\n\\nOpinions clashing,\\nEcho chambers amplify,\\nTruth' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--7ee96e0b-28ee-4eb7-a185-95539748472c' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
      "content=' sought, hard to find.\\n\\nCreators building,\\nWorlds of wonder, block by block,\\nSharing, gaining fans.\\n\\nAlgorithms sift,\\nCurating feeds, shaping views,\\nPower, unseen hand.\\n\\nComments flow like streams' additional_kwargs={} response_metadata={'safety_ratings': []} id='run--7ee96e0b-28ee-4eb7-a185-95539748472c' usage_metadata={'input_tokens': 0, 'output_tokens': 0, 'total_tokens': 0, 'input_token_details': {'cache_read': 0}}\n",
      "content=',\\nSome nurture, some erode trust,\\nA digital sea.\\n\\nContent lives and breathes,\\nA reflection of ourselves,\\nWorld mirrored online.\\n' additional_kwargs={} response_metadata={'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001', 'safety_ratings': []} id='run--7ee96e0b-28ee-4eb7-a185-95539748472c' usage_metadata={'input_tokens': -2, 'output_tokens': 175, 'total_tokens': 173, 'input_token_details': {'cache_read': 0}}\n"
     ]
    }
   ],
   "source": [
    "for chunk in llm.stream(messages):\n",
    "    print(chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d2dc40d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessageChunk(content='Okay, here\\'s a haiku about user-generated content, trying to capture the \"long, long\" feeling through repetition and drawn-out imagery.  I\\'ve aimed for a sense of vastness and the echo of voices:\\n\\nWorlds bloom from each hand,\\nStories, echoes, stretch and fade,\\nLong, long, voices call.\\n', additional_kwargs={}, response_metadata={'safety_ratings': [], 'finish_reason': 'STOP', 'model_name': 'gemini-2.0-flash-001'}, id='run--10b236c8-324c-4df1-9ac6-230757087b1a', usage_metadata={'input_tokens': 10, 'output_tokens': 73, 'total_tokens': 83, 'input_token_details': {'cache_read': 0}})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stream = llm.stream(messages)\n",
    "full = next(stream)\n",
    "for chunk in stream:\n",
    "    full += chunk\n",
    "full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6bef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pg",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
